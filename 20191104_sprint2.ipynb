{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint2 機械学習スクラッチ入門"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1647</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2073</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2340</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1078</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1256</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GrLivArea  YearBuilt\n",
       "0          1710       2003\n",
       "1          1262       1976\n",
       "2          1786       2001\n",
       "3          1717       1915\n",
       "4          2198       2000\n",
       "...         ...        ...\n",
       "1455       1647       1999\n",
       "1456       2073       1978\n",
       "1457       2340       1941\n",
       "1458       1078       1950\n",
       "1459       1256       1965\n",
       "\n",
       "[1460 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "#display(train_data.head(3))\n",
    "X_df = train_data.loc[:,['GrLivArea','YearBuilt']]\n",
    "y_df = train_data.loc[:,'SalePrice']\n",
    "display(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GrLivArea', 'YearBuilt'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_splitのスクラッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "null_sum = 0\n",
    "for col in X_df.columns:\n",
    "    #欠損の補間\n",
    "    null_sum = X_df[col].isnull().sum()\n",
    "    train_length = X_df[col].count()\n",
    "    if null_sum > 0:\n",
    "        if X_df[col].dtype == object:\n",
    "            X_df[col] = X_df[col].fillna(X_df[col].mode()[1])\n",
    "        else:\n",
    "            X_df[col] = X_df[col].fillna(X_df[col].mean())\n",
    "\n",
    "\n",
    "def scratch_train_test_split(X, y,train_size=0.75):\n",
    "    \"\"\"\n",
    "    検証用データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      学習データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\" \n",
    "    #X -> random sampling, (1-train_size)*X=X_test, rest= X_train\n",
    "    \n",
    "    #Xをランダムに並べ替え\n",
    "    p=np.random.permutation(len(X))\n",
    "    randX, randy=X[p], y[p]\n",
    "    X_train, X_test=np.vsplit(randX, [int(randX.shape[0] * train_size)])\n",
    "    y_train, y_test=np.split(randy,[int(randy.size*train_size)]) \n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シンプルデータセット1\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X1 = X[random_index]\n",
    "y1 = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シンプルデータセット2作成コード\n",
    "\n",
    "X2 = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X2, y2,train_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "- ロジスティック回帰\n",
    "- SVM\n",
    "- 決定木\n",
    ">上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#検証用データの分割には問題1で作成した自作の関数を用いてください。\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_pred(model,X,y):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y,train_size=0.50)\n",
    "    \n",
    "    Ir=model()\n",
    "    Ir.fit(X_train,y_train)\n",
    "    y_pred=Ir.predict(X_test)\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    precision=precision_score(y_test, y_pred)\n",
    "    recall=recall_score(y_test, y_pred)\n",
    "    f1=f1_score(y_test, y_pred)\n",
    "    con_mat=confusion_matrix(y_test, y_pred)\n",
    "    print('accuracy: ', accuracy)\n",
    "    print('precision: ', precision)\n",
    "    print('recall: ', recall)\n",
    "    print('f1_score: ', f1)\n",
    "    print('confusion matrix:\\n', con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  <class 'sklearn.svm.classes.SVC'>\n",
      "data set 1\n",
      "accuracy:  1.0\n",
      "precision:  1.0\n",
      "recall:  1.0\n",
      "f1_score:  1.0\n",
      "confusion matrix:\n",
      " [[129   0]\n",
      " [  0 121]]\n",
      "data set 2\n",
      "accuracy:  0.45\n",
      "precision:  0.6\n",
      "recall:  0.25\n",
      "f1_score:  0.35294117647058826\n",
      "confusion matrix:\n",
      " [[6 2]\n",
      " [9 3]]\n",
      "data set 3\n",
      "accuracy:  0.92\n",
      "precision:  0.9230769230769231\n",
      "recall:  0.9230769230769231\n",
      "f1_score:  0.9230769230769231\n",
      "confusion matrix:\n",
      " [[24  2]\n",
      " [ 2 22]]\n",
      "model:  <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n",
      "data set 1\n",
      "accuracy:  1.0\n",
      "precision:  1.0\n",
      "recall:  1.0\n",
      "f1_score:  1.0\n",
      "confusion matrix:\n",
      " [[126   0]\n",
      " [  0 124]]\n",
      "data set 2\n",
      "accuracy:  0.4\n",
      "precision:  0.42857142857142855\n",
      "recall:  0.2727272727272727\n",
      "f1_score:  0.33333333333333326\n",
      "confusion matrix:\n",
      " [[5 4]\n",
      " [8 3]]\n",
      "data set 3\n",
      "accuracy:  0.8\n",
      "precision:  1.0\n",
      "recall:  0.6296296296296297\n",
      "f1_score:  0.7727272727272727\n",
      "confusion matrix:\n",
      " [[17 10]\n",
      " [ 0 23]]\n",
      "model:  <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "data set 1\n",
      "accuracy:  0.996\n",
      "precision:  1.0\n",
      "recall:  0.9921259842519685\n",
      "f1_score:  0.9960474308300395\n",
      "confusion matrix:\n",
      " [[123   0]\n",
      " [  1 126]]\n",
      "data set 2\n",
      "accuracy:  0.6\n",
      "precision:  0.6\n",
      "recall:  0.6\n",
      "f1_score:  0.6\n",
      "confusion matrix:\n",
      " [[6 4]\n",
      " [4 6]]\n",
      "data set 3\n",
      "accuracy:  0.88\n",
      "precision:  0.8333333333333334\n",
      "recall:  0.9615384615384616\n",
      "f1_score:  0.8928571428571429\n",
      "confusion matrix:\n",
      " [[25  1]\n",
      " [ 5 19]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akishimasaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/akishimasaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/akishimasaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()\n",
    "X_ir=iris.data[50:,:]\n",
    "y_ir=iris.target[50:]\n",
    "\n",
    "models = {SGDClassifier, SVC, DecisionTreeClassifier}\n",
    "\n",
    "for i in models:\n",
    "    print('model: ',i)\n",
    "    print(\"data set 1\")\n",
    "    train_pred(i,X1,y1)\n",
    "    print(\"data set 2\")\n",
    "    train_pred(i,X2,y2)\n",
    "    print(\"data set 3\")\n",
    "    train_pred(i,X_ir,y_ir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回帰問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰問題を解くコードの作成\n",
    ">線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_df)\n",
    "y = np.array(y_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y,train_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均２乗誤差:  9.656930088740988e+29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "Sg=SGDRegressor()\n",
    "Sg.fit(X_train, y_train)\n",
    "y_pred=Sg.predict(X_test)\n",
    "\n",
    "#平均二乗誤差\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse=mean_squared_error(y_test, y_pred)\n",
    "print('平均２乗誤差: ', lin_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
